{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=pd.read_csv('NASDAQOMX-NDX.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=dat.iloc[::-1]\n",
    "dat.dropna(inplace=True)\n",
    "dat = dat.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = dat[['Trade Date']]\n",
    "dat.drop('Trade Date',inplace=True,axis=1)\n",
    "dat=pd.concat([date,dat],axis=1)\n",
    "dat['Trade Date'] = pd.to_datetime(dat['Trade Date'],format='%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dat['Trade Date'],dat[\"Index Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typical(high,low,close,volume):\n",
    "    mf = ((high + low + close)/3)*volume\n",
    "    return mf     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EMA\n",
    "def EMA(data):\n",
    "    dats = data.astype(float)\n",
    "    data['EMA'] = dats.ewm(span = 20).mean()\n",
    "    return data['EMA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFI(data):\n",
    "    data = pd.DataFrame(data)\n",
    "    returns = data - data.shift(1)\n",
    "    returns.dropna()\n",
    "    up,down = returns.copy(),returns.copy()\n",
    "    up[up<0] = 0\n",
    "    down[down>0] = 0\n",
    "    upm = up.mean()\n",
    "    downm = down.abs().mean()\n",
    "    \n",
    "    mfi = 100 - (100/(1+(upm/downm)))\n",
    "    return mfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RSI\n",
    "def RSI(data):\n",
    "    data = pd.DataFrame(data)\n",
    "    returns = data - data.shift(1)\n",
    "    returns.dropna()\n",
    "    up,down = returns.copy(),returns.copy()\n",
    "    up[up<0] = 0\n",
    "    down[down>0] = 0\n",
    "    upm = up.mean()\n",
    "    downm = down.abs().mean()\n",
    "    rsi = 100 - (100/(1+(upm/downm)))\n",
    "    return rsi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MACD(ema):\n",
    "    high = 0.075 * ema\n",
    "    low = 0.15 * ema\n",
    "    macd = high - low\n",
    "    return macd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Oscillator(data):\n",
    "\n",
    "    curr = data[-1]\n",
    "    data = list(data)\n",
    "    high = max(data)\n",
    "    low = min(data)\n",
    "    so = ((curr - low)/(high - low))*100 \n",
    "    return so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['MF'] = typical(dat['High'],dat['Low'],dat['Index Value'],dat['Total Market Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['EMA'] = EMA(dat.iloc[:,[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['RSI'] = dat['Index Value'].rolling(7).apply(RSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['MFI'] = dat['MF'].rolling(7).apply(MFI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['SO'] = dat['Index Value'].rolling(7).apply(Oscillator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.index=date[\"Trade Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['MACD'] = MACD(dat.iloc[:,[7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['MACD_Signal'] = MACD(dat.iloc[:,[11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.drop(['High','Low','Total Market Value','Dividend Market Value','MF','MACD_Signal'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.drop(\"Trade Date\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = dat.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = xdata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xdata= dates.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "xdata = pd.DataFrame(scaler.fit_transform(xdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = xdata.rename({0:'Index Value',1:'EMA',2:'RSI',3:'MFI',4:'SO',5:'MACD'},axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata.index = dates.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydata = xdata['Index Value'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = xdata.drop('Index Value',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trains, y_trains = xdata[:3000],ydata[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trains = pd.DataFrame(y_trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tests, y_tests = xdata[3000:],ydata[3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tests = pd.DataFrame(y_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tests.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tests  = x_tests[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata  = xdata[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydata.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Least Squares Support Vector Regression.\"\"\"\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.gaussian_process import kernels\n",
    "from scipy.sparse import linalg\n",
    "\n",
    "\n",
    "class LSSVR(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, C=None, kernel=None, gamma=10,polyconst=1,degree=2):\n",
    "        self.supportVectors      = None\n",
    "        self.supportVectorLabels = None\n",
    "        self.C = C\n",
    "        self.polyconst = float(1)\n",
    "        self.gamma = gamma\n",
    "        self.degree = degree\n",
    "        self.kernel= kernel\n",
    "        self.idxs  = None\n",
    "        self.K = None\n",
    "        self.bias = None \n",
    "        self.alphas = None\n",
    "            \n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        \n",
    "        if type(self.idxs) == type(None):\n",
    "            self.idxs=np.full(x_train.shape[0],True, dtype=bool)\n",
    "            \n",
    "             \n",
    "        self.supportVectors      = x_train.loc[self.idxs, :]\n",
    "        self.supportVectorLabels = y_train.loc[self.idxs]\n",
    "               \n",
    "        K = self.kernel_func(self.kernel, x_train, self.supportVectors, self.gamma)\n",
    "        \n",
    "        self.K = K\n",
    "        OMEGA = K\n",
    "        OMEGA[self.idxs, np.arange(OMEGA.shape[1])] =OMEGA[self.idxs, np.arange(OMEGA.shape[1])] + 1/self.C\n",
    "        \n",
    "        D = np.zeros(np.array(OMEGA.shape) + 1)\n",
    "        D[1:,1:] = OMEGA\n",
    "        D[0, 1:] += 1\n",
    "        D[1:,0 ] += 1\n",
    "\n",
    "        n = len(self.supportVectorLabels) + 1\n",
    "        t = np.zeros(n)\n",
    "        #t = pd.DataFrame(t)                      #Comment this line while running main function, nd run this block again uncommenting this line when running optimizer fn. \n",
    "        t[1:n] = self.supportVectorLabels.values\n",
    "    \n",
    "    \n",
    "        try:\n",
    "            z = linalg.lsmr(D.T, t)[0]\n",
    "        except:\n",
    "            z = np.linalg.pinv(D).T @ t.ravel()\n",
    "\n",
    "        self.bias   = z[0]\n",
    "        self.alphas = z[1:]\n",
    "        self.alphas = self.alphas[self.idxs]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        K = self.kernel_func(self.kernel, x_test, self.supportVectors, self.gamma)\n",
    "\n",
    "        return (K @ self.alphas) + self.bias\n",
    "    \n",
    "    def kernel_func(self, kernel, u, v, gamma):\n",
    "        if kernel == 'linear':\n",
    "            k = np.dot(u, v.T)\n",
    "        if kernel == 'rbf':\n",
    "            k = rbf_kernel(u, v, gamma=gamma)\n",
    "            #k = np.exp(-1.0*self.gamma*np.dot(np.subtract(v,u).T,np.subtract(v,u))) #rbf expression\n",
    "        if kernel == 'polynomial':\n",
    "            k = (np.dot(u,v.T) + self.polyconst)**self.degree\n",
    "\n",
    "            \n",
    "        return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Least Squares Support Vector Regression.\"\"\"\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.gaussian_process import kernels\n",
    "from scipy.sparse import linalg\n",
    "\n",
    "\n",
    "class LSSVR1(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, C=None, kernel=None, gamma=10,polyconst=1,degree=2):\n",
    "        self.supportVectors      = None\n",
    "        self.supportVectorLabels = None\n",
    "        self.C = C\n",
    "        self.polyconst = float(1)\n",
    "        self.gamma = gamma\n",
    "        self.degree = degree\n",
    "        self.kernel= kernel\n",
    "        self.idxs  = None\n",
    "        self.K = None\n",
    "        self.bias = None \n",
    "        self.alphas = None\n",
    "            \n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        \n",
    "        if type(self.idxs) == type(None):\n",
    "            self.idxs=np.full(x_train.shape[0],True, dtype=bool)\n",
    "            \n",
    "             \n",
    "        self.supportVectors      = x_train.loc[self.idxs, :]\n",
    "        self.supportVectorLabels = y_train.loc[self.idxs]\n",
    "               \n",
    "        K = self.kernel_func(self.kernel, x_train, self.supportVectors, self.gamma)\n",
    "        \n",
    "        self.K = K\n",
    "        OMEGA = K\n",
    "        OMEGA[self.idxs, np.arange(OMEGA.shape[1])] =OMEGA[self.idxs, np.arange(OMEGA.shape[1])] + 1/self.C\n",
    "        \n",
    "        D = np.zeros(np.array(OMEGA.shape) + 1)\n",
    "        D[1:,1:] = OMEGA\n",
    "        D[0, 1:] += 1\n",
    "        D[1:,0 ] += 1\n",
    "\n",
    "        n = len(self.supportVectorLabels) + 1\n",
    "        t = np.zeros(n)\n",
    "        t = pd.DataFrame(t)                      #Comment this line while running main function, nd run this block again uncommenting this line when running optimizer fn. \n",
    "        t[1:n] = self.supportVectorLabels.values\n",
    "    \n",
    "    \n",
    "        try:\n",
    "            z = linalg.lsmr(D.T, t)[0]\n",
    "        except:\n",
    "            z = np.linalg.pinv(D).T @ t.ravel()\n",
    "\n",
    "        self.bias   = z[0]\n",
    "        self.alphas = z[1:]\n",
    "        self.alphas = self.alphas[self.idxs]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        K = self.kernel_func(self.kernel, x_test, self.supportVectors, self.gamma)\n",
    "\n",
    "        return (K @ self.alphas) + self.bias\n",
    "    \n",
    "    def kernel_func(self, kernel, u, v, gamma):\n",
    "        if kernel == 'linear':\n",
    "            k = np.dot(u, v.T)\n",
    "        if kernel == 'rbf':\n",
    "            k = rbf_kernel(u, v, gamma=gamma)\n",
    "            #k = np.exp(-1.0*self.gamma*np.dot(np.subtract(v,u).T,np.subtract(v,u))) #rbf expression\n",
    "        if kernel == 'polynomial':\n",
    "            k = (np.dot(u,v.T) + self.polyconst)**self.degree\n",
    "\n",
    "            \n",
    "        return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PSO\n",
    "#--- MAIN ---------------------------------------------------------------------+\n",
    "\n",
    "class Particle:\n",
    "    def __init__(self,bounds):\n",
    "        self.position_i=[]          # particle position\n",
    "        self.velocity_i=[]          # particle velocity\n",
    "        self.pos_best_i=[]          # best position individual\n",
    "        self.err_best_i=-1          # best error individual\n",
    "        self.err_i=-1               # error individual\n",
    "\n",
    "        for i in range(0,num_dimensions):\n",
    "            self.velocity_i.append(random.uniform(-1,1))\n",
    "            self.position_i.append(random.uniform(bounds[i][0],bounds[i][1]))\n",
    "\n",
    "    # evaluate current fitness\n",
    "    def evaluate(self,costFunc):\n",
    "        self.err_i=costFunc(self.position_i)\n",
    "\n",
    "        # check to see if the current position is an individual best\n",
    "        if self.err_i<self.err_best_i or self.err_best_i==-1:\n",
    "            self.pos_best_i=self.position_i.copy()\n",
    "            self.err_best_i=self.err_i\n",
    "                    \n",
    "    # update new particle velocity\n",
    "    def update_velocity(self,pos_best_g):\n",
    "        w=0.5       # constant inertia weight (how much to weigh the previous velocity)\n",
    "        c1=1        # cognative constant\n",
    "        c2=2        # social constant\n",
    "        \n",
    "        for i in range(0,num_dimensions):\n",
    "            r1=random.random()\n",
    "            r2=random.random()\n",
    "            \n",
    "            vel_cognitive=c1*r1*(self.pos_best_i[i]-self.position_i[i])\n",
    "            vel_social=c2*r2*(pos_best_g[i]-self.position_i[i])\n",
    "            self.velocity_i[i]=w*self.velocity_i[i]+vel_cognitive+vel_social\n",
    "\n",
    "    # update the particle position based off new velocity updates\n",
    "    def update_position(self,bounds):\n",
    "        for i in range(0,num_dimensions):\n",
    "            self.position_i[i]=self.position_i[i]+self.velocity_i[i]\n",
    "            \n",
    "            # adjust maximum position if necessary\n",
    "            if self.position_i[i]>bounds[i][1]:\n",
    "                self.position_i[i]=bounds[i][1]\n",
    "\n",
    "            # adjust minimum position if neseccary\n",
    "            if self.position_i[i]<bounds[i][0]:\n",
    "                self.position_i[i]=bounds[i][0]\n",
    "        \n",
    "        \n",
    "def PSO(costFunc, bounds, num_particles, maxiter, verbose=False):\n",
    "    global num_dimensions\n",
    "\n",
    "    num_dimensions=len(bounds)\n",
    "    err_best_g=-1                   # best error for group\n",
    "    pos_best_g=[]                   # best position for group\n",
    "\n",
    "    # establish the swarm\n",
    "    swarm=[]\n",
    "    for i in range(0,num_particles):\n",
    "        swarm.append(Particle(bounds))\n",
    "\n",
    "    # begin optimization loop\n",
    "    i=0\n",
    "    while i<maxiter:\n",
    "        if verbose: print(f'iter: {i:>4d}, best solution: {err_best_g:10.6f}')\n",
    "            \n",
    "        # cycle through particles in swarm and evaluate fitness\n",
    "        for j in range(0,num_particles):\n",
    "            swarm[j].evaluate(costFunc)\n",
    "\n",
    "            # determine if current particle is the best (globally)\n",
    "            if swarm[j].err_i<err_best_g or err_best_g==-1:\n",
    "                pos_best_g=list(swarm[j].position_i)\n",
    "                err_best_g=float(swarm[j].err_i)\n",
    "        \n",
    "        # cycle through swarm and update velocities and position\n",
    "        for j in range(0,num_particles):\n",
    "            swarm[j].update_velocity(pos_best_g)\n",
    "            swarm[j].update_position(bounds)\n",
    "        i+=1\n",
    "\n",
    "    # print final results\n",
    "    print('\\nFINAL SOLUTION:')\n",
    "    print(f'   > {pos_best_g}')\n",
    "    print(f'   > {err_best_g}\\n')\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_count=10 \n",
    "\n",
    "def load_csvdata():\n",
    "    global X\n",
    "    global Y\n",
    "    \n",
    "    X = xdata\n",
    "    Y = ydata\n",
    "\n",
    "def svrPso(params):\n",
    "    kf = TimeSeriesSplit(n_splits=fold_count)\n",
    "    for train, test in kf.split(X):\n",
    "        Total = 0\n",
    "         \n",
    "        X_train, X_test, y_train, y_test = X.iloc[train], X.iloc[test], Y.iloc[train], Y.iloc[test]\n",
    "        nn = LSSVR(kernel = 'rbf',C=params[0], gamma = params[1])#Change Kernel name here(for poly kernel add 2 more parameters to optimize[degree,polyconst])\n",
    "        nn.fit(X_train,y_train)\n",
    "        result = nn.predict(X_test);\n",
    "        thisError = calsError(y_test, result)\n",
    "        Total = Total + thisError    \n",
    "    ErrorCV = Total/fold_count; \n",
    "    print('Optimizing the Parameters ..... C = {c}, gamma={e}, MSE={m}'.format(c=params[0], e=params[1], m=ErrorCV))\n",
    "    return ErrorCV\n",
    "\n",
    "def calsError(y_test, result):\n",
    "    y_pred = pd.DataFrame(result)\n",
    "    y_pred.index = y_test.index\n",
    "    data = pd.concat([y_test,y_pred],axis=1)\n",
    "    data['Error'] = (data['Index Value'] - data[0])**2\n",
    "    err = np.sqrt(np.sum(data['Error']))\n",
    "    \n",
    "    return err\n",
    "    \n",
    "def main_run():\n",
    "    \n",
    "        load_csvdata()\n",
    "    \n",
    "\n",
    "        #For PSO\n",
    "        bounds=[(0.01,1000),(0.0002,100)] \n",
    "        PSO(svrPso , bounds ,num_particles=5 ,maxiter=50)\n",
    "        \n",
    "        \n",
    "        print(\" \")\n",
    "        print(\"************ Objective Function optimized *****************\")\n",
    "        print(\" \")\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"************  Initializing Optimization *****************\")\n",
    "tic = time.time()\n",
    "main_run()\n",
    "toc = time.time()\n",
    "print(\"************  Optimization Finished *****************\")\n",
    "print('Time Taken is {time} secs'.format(time = (toc - tic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSSVR1(kernel='rbf',C =list(pos_best_g[0]),gamma = list(pos_best_g[1]))\n",
    "model.fit(x_trains,y_trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(x_tests)\n",
    "res = pd.DataFrame(res)\n",
    "res.index = y_tests.index\n",
    "res.rename({0:'Index value'},axis =1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,14))\n",
    "plt.plot(y_tests,color=\"#0A0AFF\",alpha=0.5,label=\"Test Data\")\n",
    "plt.plot(res,color=\"#AF0000\",label=\"Predections\")\n",
    "plt.title(\"Comparision of Test data and Predictions Linear Kernel\",fontsize=15)\n",
    "#blue_patch=mpatches.Patch(color=\"#0A0AFF\",label=\"Test Data\")\n",
    "#red_patch=mpatches.Patch(color=\"#AF0000\",label=\"Predictions\")\n",
    "plt.legend(fontsize=\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
